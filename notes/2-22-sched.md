# 2.22 Scheduling

## Textbook

### OSTEP

* Chapter 7
* Chapter 8

## Outline

* 工作集
* 周转时间、响应时间
* FIFO、SJF、STCF
* Round Robin 调度
* 集成 I/O
* 多级反馈队列调度算法

## Abstract

* Mechanism
	* 所谓的「机制」。
	* 底层的方法或协议。
	* 不包括具体的实现。
	* 例如，Paging、Context Switch。
* Policy
	* 策略。
	* 基于「机制」的智慧。
	* 决策算法。
	* 例如，具体的调度策略、驱逐策略。

请注意区分两者的差异。

> 本节，我们会提到「任务调度」。

## Workload

### Metrics

#### Turnaround Time

也就是「周转时间」。

定义为「任务完成时刻」和「任务到来时刻」之间的时间。

#### Average Turnaround Time

平均的周转时间。把所有任务的周转时间求和，除以参与计算的任务数量。

#### Response Time

响应时间。定义为「任务第一次被调度的时刻」和「任务到来时刻」之间的时间。

> 提出响应时间的意义在于，对于某些分时操作系统而言，「完成了一部分」的任务也有意义。但是，完全没有被调度的任务对用户而言是无意义的；因此，尽量减少干等时间，对用户体验是有好处的。

#### Average Response Time

平均响应时间。把所有任务的响应时间求和，除以参与计算的任务数量。

### Lovely Assumptions

先考虑最简单的任务模型吧。

* 每个任务都消耗相同的时间
* 所有任务都在同时到来
* 任务不可以被中途打断
* 每个任务都只用 CPU，不依赖外部设备
* 每个任务的运行时间已知

> 当然，现实生活中的任务，以上条件一个都不满足。
>
> 残酷的现实啊

### Policies

来吧，我们来试试可能的几种调度策略。

#### First In, First Out

绝对有序队列。也被称为 First Come, First Served（FCFS）。

谁先来，谁先被处理；且一直到处理完成为止，不被打断。

> 如果多个任务同时到来，随机选择一个调度。

现在我们考虑去除了「条件一」的情形，即「不同的任务消耗不同的时间」。

这样，就有可能产生 Convey Effect——来得早、耗时长的任务导致了长时间的等待。

![image-20200924151952991](2-22-sched.assets/image-20200924151952991.png)

#### Shortest Job First

吸取 FIFO 的教训，在每次「需要调度新任务」的时候，我们选择预计耗时最短的那个任务上场。

现在，在耗时时间不等的任务一齐到来之际，调度器就会先安排执行耗时短的任务，而把耗时长的任务留到最後。

![image-20200924152557106](2-22-sched.assets/image-20200924152557106.png)

但是，现在我们取消掉假设二「所有任务都一齐到来」。会怎么样呢？

![image-20200924153154806](2-22-sched.assets/image-20200924153154806.png)

情况和上面类似；只不过，B、C 比 A 稍微晚到了一点。但是造成的结果就是他们不得不等在 A 的後面——因为 A 的调度已经开始，不能被打断。

那么，我们干脆同时废除掉假设三「一旦开始，任务不能被打断」。

#### Shortest Time-to-Completion First

改进之处是，每到来一个新任务，就触发一次调度。按照「离执行完成还剩余的时间」升序排序，尽量先把「快要完成了」的任务调度上去。

因此，面对上面的情形，B、C 到来时就会触发一次调度，把 A 换下来了。

![image-20200924153523807](2-22-sched.assets/image-20200924153523807.png)

最後，我们废除掉假设五：所有任务的执行时间已知。那么，SJF 和 STCF 都无法应用了。但是，这种「打断」的思路还可以留下来。

#### Round Robin

每隔一段时间，进行一次调度。所有任务做成一圈，轮流被调度。

因为也没有办法知道每个任务的预期耗时，因此也没有必要做区分、排序了。

一个一个慢慢来吧。反正最后都会结束的。

![image-20200924154140304](2-22-sched.assets/image-20200924154140304.png)

当然，一个执行完毕的任务会从任务环中被清除；新来的任务也是插入到任务环之中。

Round Robin 的客制化策略，大概就只有一个「调度频率」的问题了。

如何决定调度频率？实际上这是一个限制问题。

* 不能调度得太频繁。
	* 调度本身也有开销。
	* 要进入、退出内核态；要保存、恢复上下文。
	* 要刷 TLB。要清理指令预测、乱序执行的痕迹。
	* 这都是要花时间的。
* 也不能调度得太稀疏。
	* 总体上会延长任务的响应时间。
	* 或许，某些任务来了很久，都没被调度上一次。

最後，我们删除假设四「任务不会和 I/O 设备通信」。

为什么这是一个重要假设呢？因为如果任务和 I/O 设备有通信，那么 I/O 设备响应时间并不会纳入其调度时间内。

同时，这一部分「等待 I/O 响应的时间」也被浪费掉了——本来可以调度调度其他程序的。

换句话说，CPU 密集型的任务相比于 I/O 密集型的任务更不占优。

![image-20200924154954335](2-22-sched.assets/image-20200924154954335.png)

> 黑色和灰色部分各自代表一次调度中，A 和 B 受到的待遇。

#### Round Robin (I/O Inc.)

把 I/O 通信纳入考虑的 RR 算法如下：

* 当一个任务发出 I/O 请求时…

	* 通过一个系统调用，把请求发给 I/O 设备。

	* 打断这个等待中的任务，并且将此任务标记为不可调度。

	* 调度下一个任务。

	* > 不能让你干等。

* 当一个任务完成 I/O 请求时…

	* 一个中断来到 CPU 处。
	* 将原任务标记回可调度，但不立即调度他。
	* 在下一次 RR 到该任务时，他会收到请求成功的消息。

要诀就是：等 I/O 设备响应（这通常非常慢）时，不要让调用任务白等着。

![image-20200924155838112](2-22-sched.assets/image-20200924155838112.png)

将 I/O 请求和 CPU 调度重叠起来，能够最大化调度效率。

##MLFQ

> 多级反馈队列调度算法（Multi-Level Feedback Queue Scheduler）。

可以看出来，RR 算法完全不考虑「任务」剩余执行时间的问题，也不考虑其「使用率」的问题。

因此，他对任何进程都是「一视同仁」地放在 Round Robin 循环队列中，按照循环往复的规律调度他们。

但是，实际上我们有办法可以学习每个任务的「特性」，从而给出更好的调度策略。

### Idea

首先，Round Robin 策略使得总体的 Response Time 大幅减小——总能够在数次循环中被调度到。但是，由于调度本身也要花时间，所以总体的 Turnaround Time 会受影响。

当然、当然，我们知道最理想的方法就是「先把短时间内任务放入循环队列」，然后那些耗时长的就在後面慢慢来、一次来久一点，以免浪费调度时间。

但是问题是，不像 STCF 算法，这里我们是不能知道「每个任务还剩多少时间」的。

无法知道未来的事情（这个任务会在多久之後结束？），只能通过过去的事情进行推测。随着调度的进程来了解每个任务的特性，从而实现更好的调度。

### Rule

首先，不像普通的、只有一条队列的 RR 算法，MLFQ 维护多条不同优先级的队列。

同一时刻到来的人物，按照下面的规则决定谁被调度：

* 如果 A 的优先级高于 B，那么调度 A 而不调度 B
* 如果 A 的优先级等于 B（存在相同的高优先级任务），则 A 和 B 以 RR 形式调度

如果只是这两条规则，那么低优先级的任务就永远不能被调度了。我们还有决定优先级的附加规则：

* 刚进入系统的新任务永远被置于最高优先级
* 如果一个任务用完了整个调度时间片、被 OS 强迫打断，那么在此之後降低其优先级 1 位
* 如果一个任务在调度时间片结束之前主动放弃 CPU 时间，则保持原优先级不变

> 这样，因为已知「比较耗时」的任务会进入较低优先级，因此我们可以适当延长低优先级任务运行时的调度时间片，减少耗时。

### Advantages

* 自动实现了 SJF（或者说 STCF）的效果。

![image-20200927093200359](2-22-sched.assets/image-20200927093200359.png)

小任务（耗时短的）自然而然地排到了高优先级。中途来的任务会及时被调度。

![image-20200927093322918](2-22-sched.assets/image-20200927093322918.png)

由于程序在进行 I/O 请求时会自主放弃 CPU 时间，因此也就实现了 I/O 密集型程序和 CPU 密集型程序的混合调度。

### Problems

这一策略同样存在很多问题：

* Starvation（饿死）

假如系统中存在多个高优先级的、交互式的（会自主放弃 CPU 时间的）任务，那么他们的优先级地位始终不会降低，从而导致其他低优先级的任务饿死。

* Scheduler Fraud（欺骗调度器）

故意在「调度时间片」快要结束时 `yield`（放弃 CPU 时间）或者进行一个 I/O 请求，以保住自己的优先级不降低。可能导致 CPU 利用率下降。

* Behavior Change（行为改变）

不能保证每个程序所进行的任务都是类似规模的；这一情形很可能在运行时改变。

## MLFQ with PB

> With Priority Boost。

### Additional Rule

只是多加了一条规则：

* 每经过固定的时间 $S$（要显著地长于调度时间片）後，所有任务都置回最高优先级。

> 这一过程称之为 Priority Boost（优先级飞升）。

这就解决了问题一：没有任务会饿死。他们总有机会在 PB 之後得到调度。

也解决了问题三：行为改变的话，会在 PB 之後反映出来，得到公平对待。

![image-20200927094734589](2-22-sched.assets/image-20200927094734589.png)

### Problem Two?

至于问题二？有很多解决方法。例如：

* 随机化调度时间片
	* 不让程序知道具体的调度时间
* 强制掉级
	* 如果一个任务在某一优先级执行时间和到一定长度（而不论其具体 yield 了多少次），就强制降低其优先级。

![image-20200927095019832](2-22-sched.assets/image-20200927095019832.png)

这样，即便是狡诈的程序也无法欺骗调度器了——他的优先级会不可避免地掉下来。

### Parameterized

比起这个，我们更关心的是：如何「模型化」一个「MLFQpb」调度模型？

因为一个 MLFQdb 策略是具体的：多少个队列？时间片多长？多久进行一次 Boost？

毫无疑问，设定这些参数也会影响具体的调度效率。

定性地来看下面几种设计策略：

#### Lower Priority, Longer Quanta

优先级越低，给予越长的调度时间片。

这也符合我们的预期：那些耗时很长的任务，应该尽量低频率地给予调度，但是加长每次调度的时长。

![image-20200927101931653](2-22-sched.assets/image-20200927101931653.png)

#### Customized

要得出一个所有系统都适用的配置方法是不现实的；通常我们会将具体的配置抽离到一个配置文件中，并交给系统管理员进行配置。

#### Solaris' Implementation

Solaris 系统会生成调度中每个任务的优先级变化情况（包括 Sink 和 Boost）。管理员可以以此作为调整参数的数据基础。

## Summary

* MLFQ 的五大原则
	* 高优先级先运行
	* 同等高任务退化为 R & R's 运行
	* 新人有最高优先级
	* 如果某任务用完了本次的时间片、或是在该优先级的总计时间达到上限，则降低其优先级；否则，保持其优先级不变
	* 经过一定时间（$S$）之后均贫富，所有任务都回到最高优先级

大量的现代操作系统都采用这一调度策略，如 BSD、Solaris、Windows NT 等。

